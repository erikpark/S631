beta0 = 1 #assigns value to beta 1
beta1 = .5
sigma_2 = 100
n = 20
?set.seed
set.seed(631) # set.seed is used to introduce a random seed
x = sample(50:100, n, replace = T)
x
x[3]
set.seed(631) # set.seed is used to introduce a random seed
x = sample(50:100, n, replace = T)
x
set.seed(631) # set.seed is used to introduce a random seed
x = sample(50:100, n, replace = TRUE)
x[n] = 120 # a vector of values for the predictor
set.seed(631) # set.seed is used to introduce a random seed
x = sample(50:100, n, replace = TRUE)
x
x[n] = 120 # a vector of values for the predictor
x
?rnorm
?pnorm
e = rnorm(n, mean = 0, sd = sqrt(sigma_2))
y = beta0+beta1*x+e
y
plot(y ~ x)
abline(beta0, beta1)
abline(lm(y ~ x), lty = 2)
require(alr4)
summary(Forbes)
attach(Forbes)
SXX = sum((bp-mean(bp))^2)
SXY = sum((bp-mean(bp))*(lpres-mean(lpres)))
SYY = sum((lpres-mean(lpres))^2)
betahat1 = SXY/SXX
betahat0 = as.numeric(mean(lpres) - betahat1 * mean(bp))
print(c(betahat0 = betahat0, betahat1 = betahat1),
digits = 4)
RSS = SYY - SXY^2/SXX
RSS
m1 = lm(lpres~bp,Forbes)
m1
attributes(m1)
m1$coefficients
summary(m1)
beta0 = 1 #assigns value to beta 1
beta1 = .5
sigma_2 = 100
for (i in 1:sim){
e = rnorm(n, mean = 0, sd = sqrt(sigma_2))
y = beta0+beta1*x+e # only thing changing here is the errors "e", but y will still change.
m1 = lm(y ~ x)
bh1.vec[i] = coef(m1)[2]
bh0.vec[i] = coef(m1)[1]
#abline(lm(y ~ x), lty = 2, col = i)
}
sim = 1000
bh1.vec = rep(0,sim)
bh0.vec = rep(0,sim)
for (i in 1:sim){
e = rnorm(n, mean = 0, sd = sqrt(sigma_2))
y = beta0+beta1*x+e # only thing changing here is the errors "e", but y will still change.
m1 = lm(y ~ x)
bh1.vec[i] = coef(m1)[2]
bh0.vec[i] = coef(m1)[1]
#abline(lm(y ~ x), lty = 2, col = i)
}
sim = 10000
bh1.vec = rep(0,sim)
bh0.vec = rep(0,sim)
for (i in 1:sim){
e = rnorm(n, mean = 0, sd = sqrt(sigma_2))
y = beta0+beta1*x+e # only thing changing here is the errors "e", but y will still change.
m1 = lm(y ~ x)
bh1.vec[i] = coef(m1)[2]
bh0.vec[i] = coef(m1)[1]
#abline(lm(y ~ x), lty = 2, col = i)
}
mean(bh0.vec)
sd(bh0.vec)
mean(bh0.vec)
mean(bh1.vec)
sd(bh1.vec)
?rchisq
set.seed(1031)
n.means = 1000
y.means = rchisq(n.means,2)
y.means
y.means = sort(y.means)
y.means
beta0 = -3
beta1 = .08
x = (y.means-beta0)/beta1
x
n.values = 1000
y.vec = rep(0,n.values*length(y.means))
for (i in 1:length(y.means)){
ei = rnorm(n.values, mean = 0, sd = 1)
yi = beta0 + beta1*x[i] + ei
y.vec[(n.values*(i-1)+1):(n.values*i)] = yi
}
?rep
x.vec = rep(x, each = n.values)
head(x.vec)
str(x.vec)
summary(x.vec)
summary(x)
?sample
samp1 = sample(1:(n.means*n.values),100)
plot(x.vec[samp1],y.vec[samp1]) # Plot of 100 points sampled from the random simulation of 1000 points.
x.vec[samp1]
samp1
x.vec
x.vec[samp1]
samp1
library(alr4)
scatterplotMatrix(~x.vec[samp1]+y.vec[samp1])
require(alr4)
str(UN11) # shows structure of data
un11 = UN11[,c("ppgdp", "fertility", "lifeExpF")]
summary(un11)
head(un11)
scatterplotMatrix(~ ppgdp + fertility + lifeExpF, data = un11)
scatterplotMatrix(~ ppgdp + fertility + lifeExpF,
smooth=FALSE, diagonal="none", data = un11)
scatterplotMatrix(~ log(ppgdp) + fertility + lifeExpF,
smooth=FALSE, data = un11) # After adding in a log transformation for ppgdp, really improves the fit of the model and evens out the distribution.
scatterplotMatrix(~ log(ppgdp) + fertility + lifeExpF,
smooth=FALSE, diagonal="none", data = un11)
m1=lm(lifeExpF ~ log(ppgdp),un11)
m1
m1
summary(m1)
m2=lm(lifeExpF ~ fertility, un11)
m2
summary(m2)
m.full <- lm(lifeExpF ~ log(ppgdp) + fertility, data=un11)
m.full
summary(m.full) # Together, the two predictors explain more than they do seperately, but it isn't additive.  There is a relationship between fertility and ppgdp, so there is overlap between what they explain.
oldpar = par(mfrow=c(1, 2))
plot(lifeExpF ~ log(ppgdp),un11)
abline(m1)
plot(lifeExpF ~ fertility,un11)
abline(m2)
par(oldpar)
scatterplotMatrix(~ log(ppgdp) + fertility + lifeExpF,
smooth=FALSE, data = un11) # After adding in a log transformation for ppgdp, really improves the fit of the model and evens out the distribution.
oldpar = par(mfrow=c(1, 2))
plot(lifeExpF ~ log(ppgdp),un11)
abline(m1)
plot(lifeExpF ~ fertility,un11)
abline(m2)
par(oldpar)
m_2on1 <- lm(fertility ~ log(ppgdp), un11)
summary(m_2on1) # From R^2 we see that 52% of changes in fertility are explained by changes in ppgdp.
plot(fertility ~ log(ppgdp), un11)
abline(m_2on1)
oldpar = par(mfrow=c(1, 2))
m_resid <- lm(resid(m1) ~ resid(m_2on1))
plot(resid(m1) ~ resid(m_2on1))
abline(m_resid, col="Red")
plot(lifeExpF ~ fertility,un11)
abline(m2, col="Red")
par(oldpar)
m.full <- lm(lifeExpF ~ log(ppgdp) + fertility, data=un11)
avPlots(m.full, id.n=0) # equivalent to finding the residuals, running the regression of the residuals, and looking at the effects.
coef(m2)
coef(m.full) # Can interpret log(ppgdp) and fertiltiy alone, by saying that they are the changes you see in Y by increasing one unit of them, keeping all others constant. (Y increases by 2.42 for every unit increase in log(ppgdp))
summary(m.full)
rm(list=ls())
require(alr4)
options(digits=3)
head(fuel2001)
help(fuel2001)
str(fuel2001)
summary(fuel2001)
fuel2001 <- transform(fuel2001,
Dlic=1000 * Drivers/Pop,
Fuel=1000 * FuelC/Pop,
Income = Income/1000,
logMiles = log(Miles))
?transform
fuel2001s = fuel2001[, c("Fuel", "Dlic", "Income", "Tax", "logMiles")]
fuel2001 <- transform(fuel2001,
Dlic=1000 * Drivers/Pop,
Fuel=1000 * FuelC/Pop,
Income = Income/1000,
logMiles = log(Miles))
View(fuel2001)
View(fuel2001s)
View(fuel2001)
summary(fuel2001s)
scatterplotMatrix(~ Tax+Dlic+Income+logMiles+Fuel,
data=fuel2001,
diagonal="none",
smoother=FALSE)
scatterplotMatrix(~ Tax+Dlic+Income+logMiles+Fuel,
data=fuel2001,
diagonal="none")
scatterplotMatrix(~ Tax+Dlic+Income+logMiles+Fuel,
data=fuel2001,
diagonal="none",
smoother=FALSE)
# Simulation
set.seed(1031)
n.means = 1000
y.means = rchisq(n.means,2)
y.means = sort(y.means)
beta0 = -3
beta1 = .08
x = (y.means-beta0)/beta1
n.values = 1000
y.vec = rep(0,n.values*length(y.means))
for (i in 1:length(y.means)){
ei = rnorm(n.values, mean = 0, sd = 1)
yi = beta0 + beta1*x[i] + ei
y.vec[(n.values*(i-1)+1):(n.values*i)] = yi
}
n.values = 1000
y.vec = rep(0,n.values*length(y.means))
for (i in 1:length(y.means)){
ei = rnorm(n.values, mean = 0, sd = 1)
yi = beta0 + beta1*x[i] + ei
y.vec[(n.values*(i-1)+1):(n.values*i)] = yi
}
x.vec = rep(x, each = n.values)
samp1 = sample(1:(n.means*n.values),100)
plot(x.vec[samp1],y.vec[samp1]) # Plot of 100 points sampled from the random simulation of 1000 points.
library(alr4)
scatterplotMatrix(~x.vec[samp1]+y.vec[samp1])
str(UN11) # shows structure of data
un11 = UN11[,c("ppgdp", "fertility", "lifeExpF")]
summary(un11)
head(un11)
scatterplotMatrix(~ ppgdp + fertility + lifeExpF, data = un11)
scatterplotMatrix(~ ppgdp + fertility + lifeExpF,
smooth=FALSE, diagonal="none", data = un11)
scatterplotMatrix(~ log(ppgdp) + fertility + lifeExpF,
smooth=FALSE, data = un11) # After adding in a log transformation for ppgdp, really improves the fit of the model and evens out the distribution.
scatterplotMatrix(~ log(ppgdp) + fertility + lifeExpF,
smooth=FALSE, diagonal="none", data = un11)
m1=lm(lifeExpF ~ log(ppgdp),un11)
m1
summary(m1)
m2=lm(lifeExpF ~ fertility, un11)
m2
summary(m2)
m.full <- lm(lifeExpF ~ log(ppgdp) + fertility, data=un11)
m.full
summary(m.full) # Together, the two predictors explain more than they do seperately, but it isn't additive.  There is a relationship between fertility and ppgdp, so there is overlap between what they explain.
oldpar = par(mfrow=c(1, 2))
plot(lifeExpF ~ log(ppgdp),un11)
abline(m1)
plot(lifeExpF ~ fertility,un11)
abline(m2)
par(oldpar) # Plots show relationship (correlation) between life expentency and ppgdp.
m_2on1 <- lm(fertility ~ log(ppgdp), un11)
summary(m_2on1) # From R^2 we see that 52% of changes in fertility are explained by changes in ppgdp.
plot(fertility ~ log(ppgdp), un11)
abline(m_2on1)
oldpar = par(mfrow=c(1, 2))
m_resid <- lm(resid(m1) ~ resid(m_2on1))
plot(resid(m1) ~ resid(m_2on1))
abline(m_resid, col="Red")
plot(lifeExpF ~ fertility,un11)
abline(m2, col="Red")
par(oldpar)
oldpar = par(mfrow=c(1, 2))
plot(lifeExpF ~ log(ppgdp),un11)
abline(m1)
plot(lifeExpF ~ fertility,un11)
abline(m2)
oldpar = par(mfrow=c(1, 2))
m_resid <- lm(resid(m1) ~ resid(m_2on1))
plot(resid(m1) ~ resid(m_2on1))
abline(m_resid, col="Red")
plot(lifeExpF ~ fertility,un11)
abline(m2, col="Red")
par(oldpar)
m.full <- lm(lifeExpF ~ log(ppgdp) + fertility, data=un11)
avPlots(m.full, id.n=0) # equivalent to finding the residuals, running the regression of the residuals, and looking at the effects.
coef(m2)
coef(m.full) # Can interpret log(ppgdp) and fertiltiy alone, by saying that they are the changes you see in Y by increasing one unit of them, keeping all others constant. (Y increases by 2.42 for every unit increase in log(ppgdp))
summary(m.full)
coef(m.full) # Can interpret log(ppgdp) and fertiltiy alone, by saying that they are the changes you see in Y by increasing one unit of them, keeping all others constant. (Y increases by 2.42 for every unit increase in log(ppgdp))
rm(list=ls())
require(alr4)
options(digits=3)
head(fuel2001)
help(fuel2001)
str(fuel2001)
summary(fuel2001)
fuel2001 <- transform(fuel2001,
Dlic=1000 * Drivers/Pop,
Fuel=1000 * FuelC/Pop,
Income = Income/1000,
logMiles = log(Miles))
fuel2001s = fuel2001[, c("Fuel", "Dlic", "Income", "Tax", "logMiles")]
summary(fuel2001s)
scatterplotMatrix(~ Tax+Dlic+Income+logMiles+Fuel,
data=fuel2001,
diagonal="none",
smoother=FALSE)
scatterplotMatrix(~ Tax+Dlic+Income+logMiles+Fuel,
data=fuel2001,
diagonal="none")
# we could also use the correlation matrix (as a complement)
cor(fuel2001s)
#f <- fuel2001[,c(7, 8, 3, 10, 9)]
#f1 <- fuel2001[,c(7, 8, 3)]
#summary(f1)
apply(fuel2001s, 2, sd)
m.fuel = lm(Fuel ~ Tax + Dlic + Income + logMiles , data = fuel2001)
summary (m.fuel)
avPlots(m.fuel)
confint(m.fuel)
summary(fuel2001s)
predict(m.fuel, newdata=data.frame(Tax = 20, Dlic = 865, Income = 25, logMiles = 10 ),
interval="confidence",
level=.98)
# Matrix algebra in R
X = model.matrix(Fuel ~ ., fuel2001s)
head(X)
dim(X)
n = dim(X)[1]
p1 = dim(X)[2]
Y = fuel2001s$Fuel
H = X%*%solve(t(X)%*% X)%*%t(X)
Bhat = solve(t(X)%*% X)%*%t(X)%*%Y
Bhat
Yhat = H%*%Y
ehat = Y - Yhat
Id = diag(n)
RSS = t(Y)%*%(Id-H)%*%Y
RSS
one = rep(1,n)
J = one%*%t(one)
dim(J)
SSreg = t(Y)%*%(H - 1/n*J)%*%Y
SYY = t(Y)%*%(Id - 1/n*J)%*%Y
c(SYY, SSreg+RSS)
R_2 = SSreg/SYY
R_2
s_hat = sqrt(RSS/(n - p1))
s_hat * sqrt(diag(solve(t(X)%*%X)))
summary(m.fuel)
